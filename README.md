# Umico_Scrapping
# Umico Scraping and Data Cleaning  

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mirhuseyn-Javadzada/UMICO_SCRAPPING_FILE/blob/main/UMICO_SCRAPPING_FILE.ipynb)





## Overview  
This project demonstrates how to collect product data from **Umico.az** using web scraping techniques and then clean the data for further analysis. The main goal is to extract useful product information (such as titles, prices, and descriptions) and prepare it in a structured format.  

The notebook shows the entire workflow starting from **scraping raw HTML** to building a **clean dataset** that can be used for future machine learning or analytical tasks.  

---

## Steps Covered  

1. **Web Scraping**  
   - Accessing product pages from Umico.az  
   - Extracting product attributes such as name, price, and details  
   - Storing raw data in a structured format using `pandas`  

2. **Data Cleaning**  
   - Removing unnecessary symbols and HTML tags  
   - Handling missing values and duplicates  
   - Normalizing text (lowercasing, trimming, regex cleaning)  

3. **Final Dataset**  
   - Cleaned product dataset ready for further use  
   - Example: exporting to CSV or analyzing with Python libraries  

---

## Technologies Used  
- **Python 3**  
- **Libraries:**  
  - `requests`, `BeautifulSoup` → scraping HTML content  
  - `pandas` → handling and cleaning structured data  
  - `re` (Regular Expressions) → advanced text cleaning  

---

## How to Use  

1. Clone the repository:  
   ```bash
   git clone https://github.com/Mirhuseyn-Javadzada/Text-Summarization-Algorithm.git
   cd Text-Summarization-Algorithm

   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mirhuseyn-Javadzada/UMICO_SCRAPPING_FILE/blob/main/UMICO_SCRAPPING_FILE.ipynb)

